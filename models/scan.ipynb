{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "def horizontal_forward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行水平正向扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    # 将 NCHW 张量转置为 NHWC 格式，以便对最后一维（水平方向）进行操作\n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)\n",
    "    # 将张量展平为 (B * H, W, C) 形状\n",
    "    flattened = input_tensor.reshape(-1, W, C)\n",
    "    return flattened.view(B, H * W, C).permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def horizontal_backward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行水平反向扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    # 将 NCHW 张量转置为 NHWC 格式，以便对最后一维（水平方向）进行操作\n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)\n",
    "    # 对最后一维（水平方向）进行翻转\n",
    "    reversed_tensor = torch.flip(input_tensor, dims=[1])\n",
    "    # 将张量展平为 (B * H, W, C) 形状\n",
    "    flattened = reversed_tensor.reshape(-1, W, C)\n",
    "    return flattened.view(B, H * W, C).permute(0, 2, 1)\n",
    "\n",
    "def horizontal_backward_scan_flipfirst(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行水平反向扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    # 将 NCHW 张量转置为 NHWC 格式，以便对最后一维（水平方向）进行操作\n",
    "    input_tensor = torch.flip(input_tensor, dims=[-1])\n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)\n",
    "    # 对最后一维（水平方向）进行翻转\n",
    "    # reversed_tensor = torch.flip(input_tensor, dims=[1])\n",
    "    # 将张量展平为 (B * H, W, C) 形状\n",
    "    flattened = input_tensor.reshape(-1, W, C)\n",
    "    return flattened.view(B, H * W, C).permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def vertical_forward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行垂直正向扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    # 将 NCHW 张量转置为 NHWC 格式，以便对倒数第二维（垂直方向）进行操作\n",
    "    input_tensor = input_tensor.permute(0, 1, 3, 2)\n",
    "    print(input_tensor)\n",
    "    print(input_tensor.shape)\n",
    "    # 将张量转置为 (B * W, H, C) 形状\n",
    "    # transposed = rearrange(input_tensor, 'B H W C -> (B W) H C')\n",
    "    # return transposed.view(B, W * H, C).permute(0, 2, 1)\n",
    "    return input_tensor.flatten(2).permute(0,2,1)\n",
    "\n",
    "\n",
    "def vertical_backward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行垂直反向扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    # 将 NCHW 张量转置为 NHWC 格式，以便对倒数第二维（垂直方向）进行操作\n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)\n",
    "    # 对倒数第二维（垂直方向）进行翻转\n",
    "    reversed_tensor = torch.flip(input_tensor, dims=[2])\n",
    "    # 将张量转置为 (B * W, H, C) 形状\n",
    "    transposed = rearrange(reversed_tensor, 'B H W C -> (B W) H C')\n",
    "    return transposed.view(B, W * H, C).permute(0, 2, 1)\n",
    "\n",
    "def vertical_backward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行垂直反向扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    input_tensor = torch.flip(input_tensor, dims=[-2]).contiguous()\n",
    "    \n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)\n",
    "\n",
    "    # 将张量转置为 (B * W, H, C) 形状\n",
    "    transposed = rearrange(input_tensor, 'B H W C -> (B W) H C').contiguous()\n",
    "    return transposed.view(B, W * H, C).permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def in_horizontal_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行水平向内扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    mid = W // 2\n",
    "    # 将 NCHW 张量转置为 NHWC 格式，以便对最后一维（水平方向）进行操作\n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)\n",
    "    left_half = input_tensor[:, :, :mid, :]\n",
    "    right_half = torch.flip(input_tensor[:, :, mid:, :], dims=[2])\n",
    "    # 拼接左右两部分\n",
    "    print(\"left\", left_half.flatten())\n",
    "    print(\"right\", right_half.flatten())\n",
    "    \n",
    "    combined = torch.cat([left_half, right_half], dim=2).contiguous()\n",
    "    # 将张量展平为 (B * H, W, C) 形状\n",
    "    flattened = combined.reshape(-1, W, C).contiguous()\n",
    "    return flattened.view(B, H * W, C).permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def out_horizontal_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行水平向外扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    mid = W // 2\n",
    "    # 将 NCHW 张量转置为 NHWC 格式，以便对最后一维（水平方向）进行操作\n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)\n",
    "    left_half = torch.flip(input_tensor[:, :, :mid, :], dims=[2])\n",
    "    right_half = input_tensor[:, :, mid:, :]\n",
    "    # 拼接左右两部分\n",
    "    print(\"left\", left_half.flatten())\n",
    "    print(\"right\", right_half.flatten())    \n",
    "    combined = torch.cat([left_half, right_half], dim=2).contiguous()\n",
    "    # 将张量展平为 (B * H, W, C) 形状\n",
    "    flattened = combined.reshape(-1, W, C).contiguous()\n",
    "    return flattened.view(B, H * W, C).permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def in_vertical_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行垂直向内扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    mid = H // 2\n",
    "    # 将 NCHW 张量转置为 NHWC 格式，以便对倒数第二维（垂直方向）进行操作\n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)\n",
    "    top_half = input_tensor[:, :mid, :, :]\n",
    "    bottom_half = torch.flip(input_tensor[:, mid:, :, :], dims=[1])\n",
    "    # 拼接上下两部分\n",
    "    print(\"top_half\",top_half.flatten())\n",
    "    print(\"bottom\", bottom_half.flatten())    \n",
    "    combined = torch.cat([top_half, bottom_half], dim=1)\n",
    "    # 将张量转置为 (B * W, H, C) 形状\n",
    "    transposed = rearrange(combined, 'B H W C -> (B W) H C').contiguous()\n",
    "    return transposed.view(B, W * H, C).permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def out_vertical_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行垂直向外扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    mid = H // 2\n",
    "    # 将 NCHW 张量转置为 NHWC 格式，以便对倒数第二维（垂直方向）进行操作\n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)\n",
    "    top_half = torch.flip(input_tensor[:, :mid, :, :], dims=[1])\n",
    "    bottom_half = input_tensor[:, mid:, :, :]\n",
    "    # 拼接上下两部分\n",
    "    # 拼接上下两部分\n",
    "    print(\"top_half\",top_half.flatten())\n",
    "    print(\"bottom\", bottom_half.flatten())       \n",
    "    combined = torch.cat([top_half, bottom_half], dim=1).contiguous()\n",
    "    # 将张量转置为 (B * W, H, C) 形状\n",
    "    transposed = rearrange(combined, 'B H W C -> (B W) H C').contiguous()\n",
    "    return transposed.view(B, W * H, C).permute(0, 2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Tensor:\n",
      " tensor([[[1.],\n",
      "         [4.],\n",
      "         [7.],\n",
      "         [2.],\n",
      "         [5.],\n",
      "         [8.],\n",
      "         [3.],\n",
      "         [6.],\n",
      "         [9.]]])\n",
      "Recovered Tensor:\n",
      " tensor([[[[1., 2., 3.],\n",
      "          [4., 5., 6.],\n",
      "          [7., 8., 9.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def vertical_forward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行垂直正向扫描\n",
    "    输入形状: (B, C, H, W)\n",
    "    变换后形状: (B, W * H, C)\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    # 交换 H 和 W 维度\n",
    "    input_tensor = input_tensor.permute(0, 1, 3, 2)  # 变为 (B, C, W, H)\n",
    "    return input_tensor.flatten(2).permute(0, 2, 1)  # 变为 (B, W*H, C)\n",
    "\n",
    "\n",
    "def vertical_forward_scan_inv(transformed_tensor, original_shape):\n",
    "    \"\"\"\n",
    "    逆变换: 复原 vertical_forward_scan 变换后的数据\n",
    "    输入形状: (B, W * H, C)\n",
    "    复原形状: (B, C, H, W)\n",
    "    \"\"\"\n",
    "    B, C, H, W = original_shape\n",
    "    # 先 permute 回 (B, C, W*H)\n",
    "    transformed_tensor = transformed_tensor.permute(0, 2, 1)  # (B, C, W*H)\n",
    "    # 复原为 (B, C, W, H)\n",
    "    recovered = transformed_tensor.view(B, C, W, H)\n",
    "    # 再交换 H 和 W 维度\n",
    "    return recovered.permute(0, 1, 3, 2)  # (B, C, H, W)\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "B, C, H, W = 1, 1, 3, 3  # 形状定义\n",
    "input_tensor = torch.tensor([[[[1, 2, 3], \n",
    "                               [4, 5, 6], \n",
    "                               [7, 8, 9]]]], dtype=torch.float32)  # (1,1,3,3)\n",
    "\n",
    "# 进行 forward 变换\n",
    "transformed = vertical_forward_scan(input_tensor)\n",
    "print(\"Transformed Tensor:\\n\", transformed)\n",
    "\n",
    "# 进行 inverse 逆变换\n",
    "recovered = vertical_forward_scan_inv(transformed, input_tensor.shape)\n",
    "print(\"Recovered Tensor:\\n\", recovered)\n",
    "\n",
    "# 验证恢复是否正确\n",
    "assert torch.allclose(input_tensor, recovered), \"Inverse transform failed!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[7., 8., 9., 4., 5., 6., 1., 2., 3.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 2., 1., 6., 5., 4., 9., 8., 7.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "def horizontal_forward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行水平正向扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    # 将 NCHW 张量转置为 NHWC 格式，以便对最后一维（水平方向）进行操作\n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)\n",
    "    # 将张量展平为 (B * H, W, C) 形状\n",
    "    flattened = input_tensor.reshape(-1, W, C)\n",
    "    return flattened.view(B, H * W, C).permute(0, 2, 1)\n",
    "\n",
    "\n",
    "def horizontal_backward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行水平反向扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    # 将 NCHW 张量转置为 NHWC 格式，以便对最后一维（水平方向）进行操作\n",
    "    input_tensor = torch.flip(input_tensor, dims=[-1])\n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)\n",
    "    # 对最后一维（水平方向）进行翻转\n",
    "    # reversed_tensor = torch.flip(input_tensor, dims=[1])\n",
    "    # 将张量展平为 (B * H, W, C) 形状\n",
    "    flattened = input_tensor.reshape(-1, W, C)\n",
    "    return flattened.view(B, H * W, C).permute(0, 2, 1)\n",
    "\n",
    "def vertical_backward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行垂直反向扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    input_tensor = torch.flip(input_tensor, dims=[-2]).contiguous()\n",
    "    \n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)\n",
    "\n",
    "    # 将张量转置为 (B * W, H, C) 形状\n",
    "    transposed = rearrange(input_tensor, 'B H W C -> (B W) H C').contiguous()\n",
    "    return transposed.view(B, W * H, C).permute(0, 2, 1)\n",
    "\n",
    "print(horizontal_backward_scan(input_tensor))\n",
    "\n",
    "horizontal_backward_scan_flipfirst(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有变换及其逆变换测试通过！\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "def horizontal_forward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行水平正向扫描\n",
    "    输入形状: (B, C, H, W)\n",
    "    变换后形状: (B, H * W, C)\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)  # (B, H, W, C)\n",
    "    flattened = input_tensor.reshape(B, H * W, C)  # (B, H * W, C)\n",
    "    return flattened.permute(0, 2, 1)  # (B, C, H * W)\n",
    "\n",
    "def horizontal_forward_scan_inv(transformed_tensor, original_shape):\n",
    "    \"\"\"\n",
    "    逆变换: 复原 horizontal_forward_scan 变换后的数据\n",
    "    输入形状: (B, C, H * W)\n",
    "    复原形状: (B, C, H, W)\n",
    "    \"\"\"\n",
    "    B, C, H, W = original_shape\n",
    "    transformed_tensor = transformed_tensor.permute(0, 2, 1)  # (B, H * W, C)\n",
    "    recovered = transformed_tensor.view(B, H, W, C)  # 复原为 (B, H, W, C)\n",
    "    return recovered.permute(0, 3, 1, 2)  # (B, C, H, W)\n",
    "\n",
    "\n",
    "def horizontal_backward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行水平反向扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    input_tensor = torch.flip(input_tensor, dims=[-1])  # 水平翻转 (B, C, H, W)\n",
    "    input_tensor = input_tensor.permute(0, 2, 3, 1)  # (B, H, W, C)\n",
    "    flattened = input_tensor.reshape(B, H * W, C)  # (B, H * W, C)\n",
    "    return flattened.permute(0, 2, 1)  # (B, C, H * W)\n",
    "\n",
    "def horizontal_backward_scan_inv(transformed_tensor, original_shape):\n",
    "    \"\"\"\n",
    "    逆变换: 复原 horizontal_backward_scan 变换后的数据\n",
    "    \"\"\"\n",
    "    B, C, H, W = original_shape\n",
    "    transformed_tensor = transformed_tensor.permute(0, 2, 1)  # (B, H * W, C)\n",
    "    recovered = transformed_tensor.view(B, H, W, C)  # (B, H, W, C)\n",
    "    recovered = recovered.permute(0, 3, 1, 2)  # (B, C, H, W)\n",
    "    return torch.flip(recovered, dims=[-1])  # 水平翻转回去\n",
    "\n",
    "\n",
    "def vertical_forward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行垂直正向扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    input_tensor = input_tensor.permute(0, 1, 3, 2)  # (B, C, W, H)\n",
    "    return input_tensor.flatten(2).permute(0, 2, 1)  # (B, W*H, C)\n",
    "\n",
    "def vertical_forward_scan_inv(transformed_tensor, original_shape):\n",
    "    \"\"\"\n",
    "    逆变换: 复原 vertical_forward_scan 变换后的数据\n",
    "    \"\"\"\n",
    "    B, C, H, W = original_shape\n",
    "    transformed_tensor = transformed_tensor.permute(0, 2, 1)  # (B, C, W*H)\n",
    "    recovered = transformed_tensor.view(B, C, W, H)  # (B, C, W, H)\n",
    "    return recovered.permute(0, 1, 3, 2)  # (B, C, H, W)\n",
    "\n",
    "\n",
    "def vertical_backward_scan(input_tensor):\n",
    "    \"\"\"\n",
    "    对输入张量进行垂直反向扫描\n",
    "    \"\"\"\n",
    "    B, C, H, W = input_tensor.shape\n",
    "    input_tensor = torch.flip(input_tensor, dims=[-2]).contiguous()  # 垂直翻转\n",
    "    input_tensor = input_tensor.permute(0, 1, 3, 2)  # (B, C, W, H)\n",
    "    return input_tensor.flatten(2).permute(0, 2, 1)  # (B, W*H, C)\n",
    "\n",
    "def vertical_backward_scan_inv(transformed_tensor, original_shape):\n",
    "    \"\"\"\n",
    "    逆变换: 复原 vertical_backward_scan 变换后的数据\n",
    "    \"\"\"\n",
    "    B, C, H, W = original_shape\n",
    "    transformed_tensor = transformed_tensor.permute(0, 2, 1)  # (B, C, W*H)\n",
    "    recovered = transformed_tensor.view(B, C, W, H)  # (B, C, W, H)\n",
    "    recovered = recovered.permute(0, 1, 3, 2)  # (B, C, H, W)\n",
    "    return torch.flip(recovered, dims=[-2])  # 垂直翻转回去\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "B, C, H, W = 1, 1, 3, 3  # 形状定义\n",
    "input_tensor = torch.tensor([[[[1, 2, 3], \n",
    "                               [4, 5, 6], \n",
    "                               [7, 8, 9]]]], dtype=torch.float32)  # (1,1,3,3)\n",
    "\n",
    "# 测试 horizontal_forward_scan\n",
    "transformed = horizontal_forward_scan(input_tensor)\n",
    "recovered = horizontal_forward_scan_inv(transformed, input_tensor.shape)\n",
    "assert torch.allclose(input_tensor, recovered), \"horizontal_forward_scan_inv failed!\"\n",
    "\n",
    "# 测试 horizontal_backward_scan\n",
    "transformed = horizontal_backward_scan(input_tensor)\n",
    "recovered = horizontal_backward_scan_inv(transformed, input_tensor.shape)\n",
    "assert torch.allclose(input_tensor, recovered), \"horizontal_backward_scan_inv failed!\"\n",
    "\n",
    "# 测试 vertical_forward_scan\n",
    "transformed = vertical_forward_scan(input_tensor)\n",
    "recovered = vertical_forward_scan_inv(transformed, input_tensor.shape)\n",
    "assert torch.allclose(input_tensor, recovered), \"vertical_forward_scan_inv failed!\"\n",
    "\n",
    "# 测试 vertical_backward_scan\n",
    "transformed = vertical_backward_scan(input_tensor)\n",
    "recovered = vertical_backward_scan_inv(transformed, input_tensor.shape)\n",
    "assert torch.allclose(input_tensor, recovered), \"vertical_backward_scan_inv failed!\"\n",
    "\n",
    "print(\"所有变换及其逆变换测试通过！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def octant_shift_grouped(x, groups=8):\n",
    "    \"\"\"\n",
    "    对 4D 张量 (NCHW) 进行分组八面移位操作。\n",
    "    :param x: 输入张量，形状为 (N, C, H, W)\n",
    "    :param groups: 分组数，默认为 8\n",
    "    :return: 位移后的特征图，形状为 (N, C * 8, H, W)\n",
    "    \"\"\"\n",
    "    N, C, H, W = x.shape\n",
    "    assert C % groups == 0, \"通道数必须能被分组数整除\"\n",
    "    channels_per_group = C // groups\n",
    "\n",
    "    # 将输入张量按通道分组\n",
    "    x_grouped = x.view(N, groups, channels_per_group, H, W)\n",
    "\n",
    "    # 定义 8 种位移方向\n",
    "    shifts = [\n",
    "        (0, 0),    # 不位移\n",
    "        (0, 1),    # 宽度方向右移\n",
    "        (0, -1),   # 宽度方向左移\n",
    "        (1, 0),    # 高度方向下移\n",
    "        (-1, 0),   # 高度方向上移\n",
    "        (1, 1),    # 右下方向位移\n",
    "        (1, -1),   # 左下方向位移\n",
    "        (-1, 1),   # 右上方向位移\n",
    "        (-1, -1),  # 左上方向位移\n",
    "    ]\n",
    "\n",
    "    # 对每一组进行八面移位\n",
    "    shifted_features = []\n",
    "    for h_shift, w_shift in shifts:\n",
    "        \n",
    "        shifted_x = torch.roll(x_grouped, shifts=(h_shift, w_shift), dims=(-2, -1))\n",
    "        shifted_features.append(shifted_x)\n",
    "\n",
    "    # 将位移结果按通道维度拼接\n",
    "    shifted_features = torch.cat(shifted_features, dim=2)  # (N, groups, C * 8, H, W)\n",
    "    shifted_features = shifted_features.view(N, -1, H, W)  # (N, C * 8, H, W)\n",
    "\n",
    "    return shifted_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class GSC(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(GSC, self).__init__()\n",
    "        self.proj3x3 = nn.Conv2d(in_channels, 4*in_channels, kernel_size=3, padding=1)\n",
    "        self.proj1x1 = nn.Conv2d(in_channels, in_channels, kernel_size=1, padding=0)\n",
    "        \n",
    "        \n",
    "        self.norm = nn.InstanceNorm2d(in_channels)\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x_residual = x\n",
    "\n",
    "        x1 = self.norm(self.bn(self.proj3x3(x)))\n",
    "        x1g = self.norm(self.bn(self.proj1x1(x)))\n",
    "        \n",
    "        x1 = x1*x1g\n",
    "        \n",
    "        x2= self.norm(self.bn(self.proj3x3(x1)))\n",
    "        \n",
    "        return x2 + x_residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsc = GSC(in_channels=1)\n",
    "from thop import \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 4])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[[1, 2, 3,4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]]], dtype=torch.float32)\n",
    "gsc = GSC(in_channels=1)\n",
    "gsc(a).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[[1, 2, 3,4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]]], dtype=torch.float32)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.,  3.,  2.,  1.,  8.,  7.,  6.,  5., 12., 11., 10.,  9., 16., 15.,\n",
       "          14., 13.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizontal_backward_scan_flipfirst(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.,  5.,  9., 13.],\n",
      "          [ 2.,  6., 10., 14.],\n",
      "          [ 3.,  7., 11., 15.],\n",
      "          [ 4.,  8., 12., 16.]]]])\n",
      "torch.Size([1, 1, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.],\n",
       "         [ 5.],\n",
       "         [ 9.],\n",
       "         [13.],\n",
       "         [ 2.],\n",
       "         [ 6.],\n",
       "         [10.],\n",
       "         [14.],\n",
       "         [ 3.],\n",
       "         [ 7.],\n",
       "         [11.],\n",
       "         [15.],\n",
       "         [ 4.],\n",
       "         [ 8.],\n",
       "         [12.],\n",
       "         [16.]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertical_forward_scan(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[13.,  9.,  5.,  1., 14., 10.,  6.,  2., 15., 11.,  7.,  3., 16., 12.,\n",
       "           8.,  4.]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertical_backward_scan(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "half tensor([ 1.,  2.,  5.,  6.,  9., 10., 13., 14.])\n",
      "right tensor([[[[ 4.],\n",
      "          [ 3.]],\n",
      "\n",
      "         [[ 8.],\n",
      "          [ 7.]],\n",
      "\n",
      "         [[12.],\n",
      "          [11.]],\n",
      "\n",
      "         [[16.],\n",
      "          [15.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  4.,  3.,  5.,  6.,  8.,  7.,  9., 10., 12., 11., 13., 14.,\n",
       "          16., 15.]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_horizontal_scan(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left tensor([ 2.,  1.,  6.,  5., 10.,  9., 14., 13.])\n",
      "right tensor([ 3.,  4.,  7.,  8., 11., 12., 15., 16.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.,  1.,  3.,  4.,  6.,  5.,  7.,  8., 10.,  9., 11., 12., 14., 13.,\n",
       "          15., 16.]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_horizontal_scan(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_half tensor([1., 2., 3., 4., 5., 6., 7., 8.])\n",
      "bottom tensor([13., 14., 15., 16.,  9., 10., 11., 12.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  5., 13.,  9.,  2.,  6., 14., 10.,  3.,  7., 15., 11.,  4.,  8.,\n",
       "          16., 12.]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_vertical_scan(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_half tensor([5., 6., 7., 8., 1., 2., 3., 4.])\n",
      "bottom tensor([ 9., 10., 11., 12., 13., 14., 15., 16.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mout_vertical_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 162\u001b[0m, in \u001b[0;36mout_vertical_scan\u001b[0;34m(input_tensor)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# 将张量转置为 (B * W, H, C) 形状\u001b[39;00m\n\u001b[1;32m    161\u001b[0m transposed \u001b[38;5;241m=\u001b[39m rearrange(combined, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB H W C -> (B W) H C\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransposed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "out_vertical_scan(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_half tensor([5., 6., 7., 8., 1., 2., 3., 4.])\n",
      "bottom tensor([ 9., 10., 11., 12., 13., 14., 15., 16.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mout_vertical_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 162\u001b[0m, in \u001b[0;36mout_vertical_scan\u001b[0;34m(input_tensor)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# 将张量转置为 (B * W, H, C) 形状\u001b[39;00m\n\u001b[1;32m    161\u001b[0m transposed \u001b[38;5;241m=\u001b[39m rearrange(combined, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB H W C -> (B W) H C\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransposed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "out_vertical_scan(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_half tensor([1., 2., 3., 4., 5., 6., 7., 8.])\n",
      "bottom tensor([13., 14., 15., 16.,  9., 10., 11., 12.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43min_vertical_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 142\u001b[0m, in \u001b[0;36min_vertical_scan\u001b[0;34m(input_tensor)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# 将张量转置为 (B * W, H, C) 形状\u001b[39;00m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m rearrange(combined, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB H W C -> (B W) H C\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransposed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "in_vertical_scan(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.,  5.,  9., 13.],\n",
      "          [ 2.,  6., 10., 14.],\n",
      "          [ 3.,  7., 11., 15.],\n",
      "          [ 4.,  8., 12., 16.]]]])\n",
      "torch.Size([1, 1, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.],\n",
       "         [ 5.],\n",
       "         [ 9.],\n",
       "         [13.],\n",
       "         [ 2.],\n",
       "         [ 6.],\n",
       "         [10.],\n",
       "         [14.],\n",
       "         [ 3.],\n",
       "         [ 7.],\n",
       "         [11.],\n",
       "         [15.],\n",
       "         [ 4.],\n",
       "         [ 8.],\n",
       "         [12.],\n",
       "         [16.]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertical_forward_scan(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3081, -1.7051, -0.6799, -0.2679, -0.1162,  1.6008,  1.6356,\n",
       "          -0.6943,  1.2421, -0.3325,  0.1871,  0.9646,  0.9783, -0.3929,\n",
       "          -0.5501,  1.2272]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.flatten(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3081],\n",
       "         [-1.7051],\n",
       "         [-0.6799],\n",
       "         [-0.2679],\n",
       "         [-0.1162],\n",
       "         [ 1.6008],\n",
       "         [ 1.6356],\n",
       "         [-0.6943],\n",
       "         [ 1.2421],\n",
       "         [-0.3325],\n",
       "         [ 0.1871],\n",
       "         [ 0.9646],\n",
       "         [ 0.9783],\n",
       "         [-0.3929],\n",
       "         [-0.5501],\n",
       "         [ 1.2272]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.flatten(2).permute(0,2,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontal Forward Scan:\n",
      "tensor([[[[ 1.,  5.,  9., 13.],\n",
      "          [ 2.,  6., 10., 14.],\n",
      "          [ 3.,  7., 11., 15.],\n",
      "          [ 4.,  8., 12., 16.]]]])\n",
      "torch.Size([1, 1, 4, 4])\n",
      "tensor([[[ 1.],\n",
      "         [ 5.],\n",
      "         [ 9.],\n",
      "         [13.],\n",
      "         [ 2.],\n",
      "         [ 6.],\n",
      "         [10.],\n",
      "         [14.],\n",
      "         [ 3.],\n",
      "         [ 7.],\n",
      "         [11.],\n",
      "         [15.],\n",
      "         [ 4.],\n",
      "         [ 8.],\n",
      "         [12.],\n",
      "         [16.]]])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.tensor([[[[1, 2, 3,4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]]], dtype=torch.float32)\n",
    "print(\"Horizontal Forward Scan:\")\n",
    "print(vertical_forward_scan(input_tensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizontal Forward Scan:\n",
      "tensor([[[1., 2., 3., 4., 5., 6., 7., 8., 9.]]])\n",
      "Horizontal Backward Scan:\n",
      "tensor([[[7., 8., 9., 4., 5., 6., 1., 2., 3.]]])\n",
      "Vertical Forward Scan:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(horizontal_backward_scan(input_tensor))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVertical Forward Scan:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvertical_forward_scan\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVertical Backward Scan:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(vertical_backward_scan(input_tensor))\n",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m, in \u001b[0;36mvertical_forward_scan\u001b[0;34m(input_tensor)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# 将张量转置为 (B * W, H, C) 形状\u001b[39;00m\n\u001b[1;32m     39\u001b[0m transposed \u001b[38;5;241m=\u001b[39m rearrange(input_tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB H W C -> (B W) H C\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransposed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 示例使用\n",
    "input_tensor = torch.tensor([[[[1, 2, 3], [4, 5, 6], [7, 8, 9]]]], dtype=torch.float32)\n",
    "\n",
    "print(\"Horizontal Forward Scan:\")\n",
    "print(horizontal_forward_scan(input_tensor))\n",
    "print(\"Horizontal Backward Scan:\")\n",
    "print(horizontal_backward_scan(input_tensor))\n",
    "print(\"Vertical Forward Scan:\")\n",
    "print(vertical_forward_scan(input_tensor))\n",
    "print(\"Vertical Backward Scan:\")\n",
    "print(vertical_backward_scan(input_tensor))\n",
    "print(\"In Horizontal Scan:\")\n",
    "print(in_horizontal_scan(input_tensor))\n",
    "print(\"Out Horizontal Scan:\")\n",
    "print(out_horizontal_scan(input_tensor))\n",
    "print(\"In Vertical Scan:\")\n",
    "print(in_vertical_scan(input_tensor))\n",
    "print(\"Out Vertical Scan:\")\n",
    "print(out_vertical_scan(input_tensor))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
