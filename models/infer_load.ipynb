{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "def get_train_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model', type=str, default=\"CMUNeXt\",\n",
    "                        choices=[\"CMUNeXt\",\"CMUNeXt_base\",\"CMUNeXt_1_3_128_256_384\",\n",
    "                                 \"CMUNeXt_cmrf\",\"CMUNeXt_rwkv_1_6_256_512_768\",\"CMUNeXt_1_6_256_512_768\",\"CMUNeXt_Depth_Conv\",\"CMUNeXt_rwkv\", \"CMUNeXt_rwkv_1_3_128_256_768\", \"CMUNeXt_Vit_SelfAttn\",\"AttU_Net\", \"TransUnet\", \"R2U_Net\", \"U_Net\",\n",
    "                                 \"UNext\", \"UNetplus\", \"UNet3plus\", \"SwinUnet\", \"MedT\", \"TransUnet\"], help='model',\n",
    "                        dest=\"model\")\n",
    "    parser.add_argument('--base-dir', type=str, default=\"./Tan9/data/busi\", help='dir',\n",
    "                        dest=\"base_dir\")\n",
    "    parser.add_argument('--train-file-dir', type=str, default=\"busi_train.txt\", help='dir',\n",
    "                        dest=\"train_file_dir\")\n",
    "    parser.add_argument('--val-file-dir', type=str, default=\"busi_val.txt\", help='dir',\n",
    "                        dest=\"val_file_dir\")\n",
    "    parser.add_argument('--base-lr', type=float, default=0.01, help='segmentation network learning rate',\n",
    "                        dest=\"base_lr\")\n",
    "    parser.add_argument('--batch-size', type=int, default=32, help='batch_size per gpu',\n",
    "                        dest=\"batch_size\")\n",
    "    parser.add_argument('--epoch', type=int, default=280, help='train epoch',\n",
    "                        dest=\"epoch\")\n",
    "    parser.add_argument('--img-size', type=int, default=256, help='img size of per batch',\n",
    "                        dest=\"img_size\")\n",
    "    parser.add_argument('--num-classes', type=int, default=1, help='seg num_classes',\n",
    "                        dest=\"num_classes\")\n",
    "    parser.add_argument('--seed', type=int, default=41, help='random seed',\n",
    "                        dest=\"seed\")\n",
    "    parser.add_argument('--dataset-name', type=str, default=\"busi\", help='Name of the dataset',\n",
    "                        dest=\"datasetname\")\n",
    "    # parser.add_argument('--model-name', type=str, default=\"CMUNeXt_Depth_Conv\", help='Name of the model',\n",
    "    #                     dest=\"modelname\")\n",
    "    return parser\n",
    "\n",
    "parser = get_train_parser()\n",
    "# args = parser.parse_known_args()\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "def load_model(model_path, args, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "    # Model selection based on argument\n",
    "    if args.model == \"CMUNeXt\":\n",
    "        model = CMUNeXt(dims=[16, 32, 128, 256,768])\n",
    "\n",
    "    # Check if multiple GPUs are available and wrap the model with DataParallel\n",
    "    # if torch.cuda.device_count() > 1:\n",
    "    #     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    #     model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Load the model weights\n",
    "    state_dict = torch.load(model_path, map_location=device, weights_only=True)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    # Move the model to the specified device\n",
    "    model.to(device)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "# rwkv\n",
    "pthpath = \\\n",
    "    '/data/hongboye/projects/checkpoint/LoRA_4_5/2024-12-28/224/poly_1_BS_4_0.8301_LoRA_4_5_model.pth'\n",
    "\n",
    "\n",
    "model = load_model(pthpath, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# args = parser.parse_known_args()\u001b[39;00m\n\u001b[1;32m     86\u001b[0m args, _ \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_known_args()        \n\u001b[0;32m---> 88\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpthpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_path, args, device)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoRA\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoRA_4_5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 52\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetwork\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv_based\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompnet1225_enc_rwkv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoRA_4_5\n\u001b[1;32m     53\u001b[0m         model \u001b[38;5;241m=\u001b[39m LoRA_4_5(dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m192\u001b[39m, \u001b[38;5;241m384\u001b[39m],num_classes\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_classes)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoRA_3_4_5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import  torch\n",
    "import argparse\n",
    "\n",
    "# rwkv\n",
    "pthpath = \\\n",
    "    '/data/hongboye/projects/checkpoint/CMUNeXt_rwkv_1_3_128_256_768/2024-12-16/115/poly_1_BS_8_0.8088_CMUNeXt_rwkv_1_3_128_256_768_model.pth'\n",
    "\n",
    "def get_train_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model', type=str, default=\"LoRA_4_5\",\n",
    "                        choices=[\"CMUNeXt\",\"CMUNeXt_base\",\"CMUNeXt_1_3_128_256_384\", \"CMUNeXt_1_6_256_512_768\",\\\n",
    "                                 \"CMUNeXt_cmrf\",\"CMUNeXt_Depth_Conv\",\\\n",
    "                                 \"CMUNeXt_rwkv_1_6_256_512_768\",\"CMUNeXt_rwkv\", \"CMUNeXt_rwkv_1_3_128_256_768\", \"CMUNeXt_rwkv_1_3_128_256_768_no_shift\", \"CMUNeXt_rwkv_zigzagBNC_1_3_128_256_768\",\\\n",
    "                                \"cmunext_rwkv_2_4_9_192_384\",\\\n",
    "                                 \"CMUNeXt_Vit_SelfAttn\",\"AttU_Net\", \"TransUnet\", \"R2U_Net\", \"U_Net\",\\\n",
    "                                 \"conv_gated_net\",\"conv_gated_net_LN\",\"conv_gated_net_randinit_SelfGate\",\\\n",
    "                                 \"compnet_\",\"lord_Brwkv_1222\",\\\n",
    "                                 \"lord_Brwkv_1222\",\"LoRA_3_6_768\",\"LoRA_woDW_3_6_768\",\"LoRA_2_4_9_384Enc\",\"LoRA_2_4_9_384\",\"LoRA_wo_dw\",\"LoRA_4_5_3_4_9_384\",\\\n",
    "                                 \"LoRA_4_5_qshift\",\"LoRA_4_5\",\"LoRA__5\",\"LoRA_3_4_5\",\\\n",
    "                                \"LoRA_dw_4_5\",\"LoRA_dw_rwkv_first_4_5\",\\\n",
    "                                 \"Restore_RWKV\",\\\n",
    "                                 \"UNext\", \"UNetplus\", \"UNet3plus\", \"SwinUnet\", \"MedT\", \"TransUnet\"], help='model',\n",
    "                        dest=\"model\")\n",
    "    parser.add_argument('--base-dir', type=str, default=\"./Tan9/data\", help='dir',\n",
    "                        dest=\"base_dir\")\n",
    "    parser.add_argument('--train-file-dir', type=str, default=\"busi_train.txt\", help='dir',\n",
    "                        dest=\"train_file_dir\")\n",
    "    parser.add_argument('--val-file-dir', type=str, default=\"busi_val.txt\", help='dir',\n",
    "                        dest=\"val_file_dir\")\n",
    "    parser.add_argument('--base-lr', type=float, default=0.01, help='segmentation network learning rate',\n",
    "                        dest=\"base_lr\")\n",
    "    parser.add_argument('--batch-size', type=int, default=32, help='batch_size per gpu',\n",
    "                        dest=\"batch_size\")\n",
    "    parser.add_argument('--epoch', type=int, default=280, help='train epoch',\n",
    "                        dest=\"epoch\")\n",
    "    parser.add_argument('--img-size', type=int, default=256, help='img size of per batch',\n",
    "                        dest=\"img_size\")\n",
    "    parser.add_argument('--num-classes', type=int, default=1, help='seg num_classes',\n",
    "                        dest=\"num_classes\")\n",
    "    parser.add_argument('--seed', type=int, default=41, help='random seed',\n",
    "                        dest=\"seed\")\n",
    "    parser.add_argument('--dataset-name', type=str, default=\"busi\", help='Name of the dataset',\n",
    "                        dest=\"datasetname\")\n",
    "    # parser.add_argument('--model-name', type=str, default=\"CMUNeXt_Depth_Conv\", help='Name of the model',\n",
    "    #                     dest=\"modelname\")\n",
    "    return parser\n",
    "\n",
    "def load_model(model_path, args, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "    # Model selection based on argument\n",
    "    if args.model.startswith(\"LoRA\"):\n",
    "        if args.model.endswith(\"LoRA_4_5\"):\n",
    "            from src.network.conv_based.compnet1225_enc_rwkv import LoRA_4_5\n",
    "            model = LoRA_4_5(dims=[24, 48, 96, 192, 384],num_classes=args.num_classes)\n",
    "        elif args.model.endswith(\"LoRA_3_4_5\"):\n",
    "            from src.network.conv_based.compnet1225_enc_rwkv import LoRA_3_4_5\n",
    "            model = LoRA_3_4_5(dims=[24, 48, 96, 192, 384],num_classes=args.num_classes)            \n",
    "        elif args.model.endswith(\"LoRA__5\"):\n",
    "            from src.network.conv_based.compnet1225_enc_rwkv import LoRA__5\n",
    "            model = LoRA__5(dims=[24, 48, 96, 192, 384],num_classes=args.num_classes)\n",
    "        elif args.model.startswith(\"LoRA_dw_4_5\"):\n",
    "            from src.network.conv_based.compnet1227_enc_test_dw import LoRA_dw_4_5\n",
    "            model = LoRA_dw_4_5()\n",
    "        elif args.model.startswith(\"LoRA_dw_rwkv_first_4_5\"):\n",
    "            from src.network.conv_based.compnet1227_enc_test_dw import LoRA_dw_rwkv_first_4_5\n",
    "            model = LoRA_dw_rwkv_first_4_5()\n",
    "\n",
    "    # Check if multiple GPUs are available and wrap the model with DataParallel\n",
    "    # if torch.cuda.device_count() > 1:\n",
    "    #     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    #     model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Load the model weights\n",
    "    state_dict = torch.load(model_path, map_location=device, weights_only=True)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    # Move the model to the specified device\n",
    "    model.to(device)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "parser = get_train_parser()\n",
    "# args = parser.parse_known_args()\n",
    "args, _ = parser.parse_known_args()        \n",
    "        \n",
    "model = load_model(pthpath, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "\n",
    "from pytorch_grad_cam import  GradCAM, GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hongboye/anaconda3/envs/rwkv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/hongboye/anaconda3/envs/rwkv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Èùû rwkv\n",
    "pthpath = '/data/hongboye/projects/checkpoint/CMUNeXt_base/2024-12-15/143/busi_BS_4_0.6730_CMUNeXt_base_model.pth'\n",
    "\n",
    "model = load_model(pthpath, args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
